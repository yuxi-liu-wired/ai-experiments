{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3075988-e802-4e74-8968-241e29a0ba27",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook plays with the [Alexandria Index](https://alex.macrocosm.so/download).\n",
    "\n",
    "First, download the datasets. \n",
    "\n",
    "Install `pyarrow` and `fastparquet` by `pip install pyarrow fastparquet`. Then copy in one of the `abstracts` parquet files from the archive, and run the next cells to load the dataset. I used the `abstracts_1.parquet` file. You can try others.\n",
    "\n",
    "First, use `%ls%` to find out where you are. Then use `%cd` to get to the notebook's folder if you are not in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "16a94ec3-9770-4e2b-bf02-d32fd4d14015",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;32mabstracts_1.parquet\u001b[0m*   \u001b[01;32mabstracts_4.parquet\u001b[0m*  \u001b[01;32mtitles_17.parquet\u001b[0m*\n",
      "\u001b[01;32mabstracts_10.parquet\u001b[0m*  \u001b[01;32mabstracts_5.parquet\u001b[0m*  \u001b[01;32mtitles_18.parquet\u001b[0m*\n",
      "\u001b[01;32mabstracts_11.parquet\u001b[0m*  \u001b[01;32mabstracts_6.parquet\u001b[0m*  \u001b[01;32mtitles_19.parquet\u001b[0m*\n",
      "\u001b[01;32mabstracts_12.parquet\u001b[0m*  \u001b[01;32mabstracts_7.parquet\u001b[0m*  \u001b[01;32mtitles_2.parquet\u001b[0m*\n",
      "\u001b[01;32mabstracts_13.parquet\u001b[0m*  \u001b[01;32mabstracts_8.parquet\u001b[0m*  \u001b[01;32mtitles_20.parquet\u001b[0m*\n",
      "\u001b[01;32mabstracts_14.parquet\u001b[0m*  \u001b[01;32mabstracts_9.parquet\u001b[0m*  \u001b[01;32mtitles_21.parquet\u001b[0m*\n",
      "\u001b[01;32mabstracts_15.parquet\u001b[0m*  \u001b[01;32malexandria.ipynb\u001b[0m*     \u001b[01;32mtitles_22.parquet\u001b[0m*\n",
      "\u001b[01;32mabstracts_16.parquet\u001b[0m*  \u001b[01;32moutput_1.txt\u001b[0m*         \u001b[01;32mtitles_23.parquet\u001b[0m*\n",
      "\u001b[01;32mabstracts_17.parquet\u001b[0m*  \u001b[01;32moutput_full.txt\u001b[0m*      \u001b[01;32mtitles_3.parquet\u001b[0m*\n",
      "\u001b[01;32mabstracts_18.parquet\u001b[0m*  \u001b[01;32mtitles_1.parquet\u001b[0m*     \u001b[01;32mtitles_4.parquet\u001b[0m*\n",
      "\u001b[01;32mabstracts_19.parquet\u001b[0m*  \u001b[01;32mtitles_10.parquet\u001b[0m*    \u001b[01;32mtitles_5.parquet\u001b[0m*\n",
      "\u001b[01;32mabstracts_2.parquet\u001b[0m*   \u001b[01;32mtitles_11.parquet\u001b[0m*    \u001b[01;32mtitles_6.parquet\u001b[0m*\n",
      "\u001b[01;32mabstracts_20.parquet\u001b[0m*  \u001b[01;32mtitles_12.parquet\u001b[0m*    \u001b[01;32mtitles_7.parquet\u001b[0m*\n",
      "\u001b[01;32mabstracts_21.parquet\u001b[0m*  \u001b[01;32mtitles_13.parquet\u001b[0m*    \u001b[01;32mtitles_8.parquet\u001b[0m*\n",
      "\u001b[01;32mabstracts_22.parquet\u001b[0m*  \u001b[01;32mtitles_14.parquet\u001b[0m*    \u001b[01;32mtitles_9.parquet\u001b[0m*\n",
      "\u001b[01;32mabstracts_23.parquet\u001b[0m*  \u001b[01;32mtitles_15.parquet\u001b[0m*\n",
      "\u001b[01;32mabstracts_3.parquet\u001b[0m*   \u001b[01;32mtitles_16.parquet\u001b[0m*\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4dce1cf3-0044-4290-afb9-c8c70d7978c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "directory_path = os.getcwd()\n",
    "filepaths = glob.glob(os.path.join(directory_path, 'abstracts_*.parquet'))\n",
    "# print(filepaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fd1afc-cdc6-4f45-9225-abf509c1af96",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exploring the `abstracts` dataset\n",
    "\n",
    "The `abstracts` dataset contains 2.25 million "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a256aff2-a41a-4dae-bce8-f1130144cf0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet(filepaths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4131ee53-211c-4977-8c9c-2db5f259b6de",
   "metadata": {},
   "source": [
    "Let's see if the data contains duplicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f32521e8-d11c-45d0-b507-2d2a292106eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "137\n"
     ]
    }
   ],
   "source": [
    "print(df[\"doi\"].duplicated().sum())\n",
    "print(df[\"abstract\"].duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389e8c88-937c-492f-9eae-68cc7a7c100a",
   "metadata": {},
   "source": [
    "We see that there are no doi duplicates, good! But what about the abstract duplicates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "788c842e-f7e8-4e2e-bcce-c4fae50fd5af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def export_duplicates(df, filename, truncation_length=100, column='abstract'):\n",
    "    with open(filename, 'w') as file:\n",
    "        duplicates = df[df.duplicated(subset=column, keep=False)]\n",
    "        truncated_df = duplicates.copy()\n",
    "        truncated_df['doi'] = truncated_df['doi'].str[:truncation_length]\n",
    "        truncated_df[column] = truncated_df[column].str.replace('\\n', ' ').str[:truncation_length]\n",
    "        \n",
    "        sorted_df = truncated_df.sort_values(by=column)\n",
    "        sorted_df[['doi', column]].to_csv(file, sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "27954ebb-4d0c-43ac-adb5-b8e5e71daba8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export_duplicates(df, \"output_1.txt\", column='abstract')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e063cb-e4f5-4725-b095-26f2465ef0c2",
   "metadata": {},
   "source": [
    "We see several types of duplicates:\n",
    "\n",
    "* Papers that are comments on other papers. For example, there are 3 papers with the same abstract: \"Comment: Expert Elicitation for Reliable System Design [arXiv:0708.0279]\".\n",
    "* Papers withdrawn, with the abstract \"This paper has been withdrawn by the author.\" or its variants.\n",
    "* Multi-part papers.\n",
    "    * For example, a series of 7 papers (\"Some series and integrals involving the Riemann zeta function...\" by Donal F. Connon) with the same abstract, because it's just one 1400-pages long paper filled with nothing but large integrals and summations. I imagine they just split it into 7 parts either due to upload limits.\n",
    "\n",
    "And as it should, every duplicate abstract has the same embedding vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03828b8f-b305-42ae-b5e8-5943ad36db87",
   "metadata": {},
   "source": [
    "Now let's import *all* the abstracts into one large dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "31310dca-9f91-4548-aa4c-b160eab15256",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for filepath in filepaths:\n",
    "    df = pd.read_parquet(filepath)\n",
    "    dfs.append(df)\n",
    "\n",
    "cdf = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e04fe8ef-98b7-4caf-b20d-9a4afd2084a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>doi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A fully differential calculation in perturba...</td>\n",
       "      <td>[-0.035151865, 0.022851437, 0.025942933, -0.02...</td>\n",
       "      <td>0704.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We describe a new algorithm, the $(k,\\ell)$-...</td>\n",
       "      <td>[0.035485767, -0.0015772493, -0.0016615744, -0...</td>\n",
       "      <td>0704.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The evolution of Earth-Moon system is descri...</td>\n",
       "      <td>[-0.014510429, 0.010210799, 0.049661566, -0.01...</td>\n",
       "      <td>0704.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We show that a determinant of Stirling cycle...</td>\n",
       "      <td>[0.029191103, 0.047992915, -0.0061754594, -0.0...</td>\n",
       "      <td>0704.0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In this paper we show how to compute the $\\L...</td>\n",
       "      <td>[-0.015174898, 0.01603887, 0.04062805, -0.0246...</td>\n",
       "      <td>0704.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2254193</th>\n",
       "      <td>A promising theory in modifying general rela...</td>\n",
       "      <td>[0.02845307, 0.010213018, -0.0065456596, 0.024...</td>\n",
       "      <td>1710.04612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2254194</th>\n",
       "      <td>We consider an $\\ell_0$-minimization problem...</td>\n",
       "      <td>[0.0020157294, 0.0043197623, 0.03604705, -0.04...</td>\n",
       "      <td>1710.04613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2254195</th>\n",
       "      <td>Given an ideal I in a polynomial ring, we co...</td>\n",
       "      <td>[0.029166956, -0.0078339875, 0.014820765, -0.0...</td>\n",
       "      <td>1710.04614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2254196</th>\n",
       "      <td>Imitation learning is a powerful paradigm fo...</td>\n",
       "      <td>[0.039186474, -0.03989054, 0.009515166, -0.056...</td>\n",
       "      <td>1710.04615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2254197</th>\n",
       "      <td>Studies of low surface brightness (LSB) gala...</td>\n",
       "      <td>[-5.4701242e-05, -0.01187254, -0.005270973, -0...</td>\n",
       "      <td>1710.04616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2254198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  abstract  \\\n",
       "0          A fully differential calculation in perturba...   \n",
       "1          We describe a new algorithm, the $(k,\\ell)$-...   \n",
       "2          The evolution of Earth-Moon system is descri...   \n",
       "3          We show that a determinant of Stirling cycle...   \n",
       "4          In this paper we show how to compute the $\\L...   \n",
       "...                                                    ...   \n",
       "2254193    A promising theory in modifying general rela...   \n",
       "2254194    We consider an $\\ell_0$-minimization problem...   \n",
       "2254195    Given an ideal I in a polynomial ring, we co...   \n",
       "2254196    Imitation learning is a powerful paradigm fo...   \n",
       "2254197    Studies of low surface brightness (LSB) gala...   \n",
       "\n",
       "                                                embeddings         doi  \n",
       "0        [-0.035151865, 0.022851437, 0.025942933, -0.02...   0704.0001  \n",
       "1        [0.035485767, -0.0015772493, -0.0016615744, -0...   0704.0002  \n",
       "2        [-0.014510429, 0.010210799, 0.049661566, -0.01...   0704.0003  \n",
       "3        [0.029191103, 0.047992915, -0.0061754594, -0.0...   0704.0004  \n",
       "4        [-0.015174898, 0.01603887, 0.04062805, -0.0246...   0704.0005  \n",
       "...                                                    ...         ...  \n",
       "2254193  [0.02845307, 0.010213018, -0.0065456596, 0.024...  1710.04612  \n",
       "2254194  [0.0020157294, 0.0043197623, 0.03604705, -0.04...  1710.04613  \n",
       "2254195  [0.029166956, -0.0078339875, 0.014820765, -0.0...  1710.04614  \n",
       "2254196  [0.039186474, -0.03989054, 0.009515166, -0.056...  1710.04615  \n",
       "2254197  [-5.4701242e-05, -0.01187254, -0.005270973, -0...  1710.04616  \n",
       "\n",
       "[2254198 rows x 3 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63277d08-d3ad-44e7-9e47-7a8677226e45",
   "metadata": {},
   "source": [
    "How much space did that take up? The `abstract` and `doi` columns each are made of ASCII characters, each costing 1 byte. So we can just count. The `embeddings` column is made of vectors of float32, each costing 4 bytes. The following calculation shows\n",
    "* `doi`: 23 MB\n",
    "* `abstract`: 2000 MB\n",
    "* `embeddings`: 6600 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "1064b99b-d835-4045-b872-46b82eca4c75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated size requirement for the 'doi' column is approximately: 22.76 MB.\n"
     ]
    }
   ],
   "source": [
    "average_length = cdf['doi'].str.len().mean()\n",
    "num_rows = len(cdf)\n",
    "size_requirement_bytes = average_length * num_rows\n",
    "size_requirement_mb = size_requirement_bytes / 1048576\n",
    "print(f\"The estimated size requirement for the 'doi' column is approximately: {size_requirement_mb:.2f} MB.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "088d8193-3629-4dd4-9f11-f61a71b6060a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated size requirement for the 'abstract' column is approximately: 2007.99 MB.\n"
     ]
    }
   ],
   "source": [
    "average_length = cdf['abstract'].str.len().mean()\n",
    "num_rows = len(cdf)\n",
    "size_requirement_bytes = average_length * num_rows\n",
    "size_requirement_mb = size_requirement_bytes / 1048576\n",
    "print(f\"The estimated size requirement for the 'abstract' column is approximately: {size_requirement_mb:.2f} MB.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "1a8bf282-52f1-45c7-b829-37cd2aba1919",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated space requirement for the 'embeddings' column is approximately: 6604.10 MB.\n"
     ]
    }
   ],
   "source": [
    "num_rows = len(cdf)\n",
    "sample_entry = cdf['embeddings'][0] \n",
    "entry_size_bytes = sample_entry.nbytes\n",
    "size_requirement_bytes = entry_size_bytes * num_rows\n",
    "size_requirement_mb = size_requirement_bytes / 1048576\n",
    "print(f\"The estimated space requirement for the 'embeddings' column is approximately: {size_requirement_mb:.2f} MB.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e935527-e8e3-4895-8e18-f911faae57b4",
   "metadata": {},
   "source": [
    "We see that it contains 2.25 million rows. Let's explore it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a10f2bd3-d8ba-454a-8fb8-630c101865e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1718\n"
     ]
    }
   ],
   "source": [
    "print(cdf[\"doi\"].duplicated().sum())\n",
    "print(cdf[\"abstract\"].duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d18605a-9eb5-4a2b-8844-6566cea8783d",
   "metadata": {},
   "source": [
    "So there are no doi duplicates, but 1718 abstract duplicates. Let's export the duplicates and see what they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "016e6128-ed43-4ea8-866b-f464fa3a9613",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export_duplicates(cdf, \"output_full.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36227104-ff3d-4136-836c-b37b2c3285b9",
   "metadata": {},
   "source": [
    "So I took a brief look and some of what I found:\n",
    "* Literally the same title and abstract, but one is longer than the other. <https://arxiv.org/abs/1907.05261>, <https://arxiv.org/abs/2006.13685>\n",
    "* <https://arxiv.org/abs/2012.12178> is an extended abstract of <https://arxiv.org/abs/2104.09611>.\n",
    "* <https://arxiv.org/abs/2303.04075> is an \"evolved version\" of <https://arxiv.org/abs/2209.12285>. Why couldn't they have submitted a second version?\n",
    "* 500 papers withdrawn. Voluntary withdrawals are usually due to mistakes that invalidate the result, or the paper being superceded by later publications. The involuntary ones are usually due to plagerism or being a jerk. Notable examples:\n",
    "    * 7 papers by N. Mebarki, A.Maireche are all plagerized.\n",
    "    * 8 papers by Ramy Naboulsi, all plagerized. The situation was apparently that Naboulsi was trying to get into Japan. As a result we got probably the [weirdest abstract](https://arxiv.org/abs/hep-ph/0304045) ever, which is just an email from Yasushi Watanabe apologizing... The whole situation is described in [Preprint server seeks way to halt plagiarists | Nature](https://www.nature.com/articles/426007a).\n",
    "    > The plagiarism case traces its origins to June 2002, when Yasushi Watanabe, a high-energy physicist at the Tokyo Institute of Technology, was contacted by Ramy Naboulsi, who said he was a mathematical physicist. Naboulsi asked for Watanabe's help in obtaining a research position in Japan. Impressed by Naboulsi's work, Watanabe agreed to upload some of his papers to ArXiv, which Naboulsi was unable to do himself as he had no academic affiliation. “I was so amazed at his productivity I began to think he was a genius,” Watanabe later wrote in an e-mail to the archive.\n",
    "    * 3 papers by Tomasz Bodziony all about how Einstein faked his relativity papers. \"withdrawn by arXiv administrators due to inflammatory content and unprofessional language\".\n",
    "    * 3 crackpot math papers by Asia Furones, \"withdrawn by arXiv admin because of the use of a pseudonym, in violation of arXiv policy\".\n",
    "    * D. L. Khokhlov voluntarily withdrew 4 papers \"due to the presented idea is wrong\". Just the direct approach, huh?\n",
    "    * 21 voluntary withdrawals due to \"crucial sign error\", 10 due to \"crucial error\".\n",
    "\n",
    "Some other arXiv trivias:\n",
    "* <https://arxiv.org/abs/1511.08771>: 11232 pages long. The main text is 102 pages long. The rest of it is basically what happens when someone has a csv file but wants to squeeze it into a pdf.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f640e8ff-3275-4aec-aeaa-f89646b12eb3",
   "metadata": {},
   "source": [
    "## Compiling a FAISS database\n",
    "\n",
    "We can quickly search over the vector database by compiling them into a FAISS database, which is optimized for fast vector searches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "c533b736-5cd5-49dd-8a8c-78cda4edf1ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Convert embeddings into a matrix (2D numpy array)\n",
    "embedding_matrix = np.vstack(cdf['embeddings'].values)\n",
    "\n",
    "# Get the dimension of the embeddings\n",
    "dimension = embedding_matrix.shape[1] \n",
    "\n",
    "# Build the FAISS index\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(embedding_matrix.astype('float32'))  # FAISS uses float32\n",
    "\n",
    "# Now, create a mapping from the index in the FAISS database to the corresponding doi and abstract.\n",
    "# The i-th entry in the FAISS index corresponds to the i-th entry in the DataFrame\n",
    "index_to_doi = cdf['doi'].values\n",
    "index_to_abstract = cdf['abstract'].values\n",
    "\n",
    "# Now, you can search the FAISS index\n",
    "def search(query_vector, k=5):\n",
    "    # Make sure query_vector is a 2D array\n",
    "    query_vector = query_vector.reshape(1, -1).astype('float32')\n",
    "    \n",
    "    _, indices = index.search(query_vector, k)\n",
    "    \n",
    "    # Convert indices to original DOIs and abstracts\n",
    "    result_doi = index_to_doi[indices]\n",
    "    result_abstract = index_to_abstract[indices]\n",
    "    result_abstract = np.array([[np.char.replace(s, '\\n', ' ') for s in row] for row in result_abstract])\n",
    "    \n",
    "    return result_doi, result_abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "4641680d-0d80-45f0-8dfd-b6cc88a90b57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from InstructorEmbedding import INSTRUCTOR\n",
    "model_ins = INSTRUCTOR('hkunlp/instructor-xl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "25456674-8eb5-4977-aff6-b0e0f3ead3e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device =  cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "INSTRUCTOR(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: T5EncoderModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False})\n",
       "  (2): Dense({'in_features': 1024, 'out_features': 768, 'bias': False, 'activation_function': 'torch.nn.modules.linear.Identity'})\n",
       "  (3): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "# Check if CUDA is available and set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device = \", device)\n",
    "model_ins.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "506d6bc5-b3b3-48d9-bea3-36cb7f9fb2f7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who else than Einstein developed relativity independently?\n",
      "--------------------------------------------------------------------------------\n",
      "[['  The intermediate stage of the development of general relativity is inseparable of Marcel Grossmann\\'s mathematical assistance. Einstein acknowledges Grossmann\\'s help during 1912-1914 to the development of general relativity. In fact, as with special relativity so was it with General relativity, Einstein received assistance only from his old friends, Marcel Grossmann and Michele Besso. However, he continued to consider Besso as his eternal \"sounding board\"... '\n",
      "  '  In 1895 Hendrik Antoon Lorentz derived the Fresnel dragging coefficient in his theory of immobile ether and electrons. This derivation did not explicitly involve electromagnetic theory at all. According to the 1922 Kyoto lecture notes, before 1905 Einstein tried to discuss Fizeau\\'s experiment \"as originally discussed by Lorentz\" (in 1895). At this time he was still under the impression that the ordinary Newtonian law of addition of velocities was unproblematic. In 1907 Max Laue showed that the Fresnel dragging coefficient would follow from a straightforward application of the relativistic addition theorem of velocities. This derivation is mathematically equivalent to Lorentz\\'s derivation of 1895. From 1907 onwards Einstein adopted Laue\\'s derivation. When Robert Shankland asked Einstein how he had learned of the Michelson-Morley experiment, Einstein told him that he had become aware of it through the writings of Lorentz, but only after 1905 had it come to his attention. \"Otherwise\", he said, \"I would have mentioned it in my paper\". He continued to say that the experimental results which had influenced him most were stellar aberration and Fizeau\\'s water tube experiment. \"They were enough\". Indeed the famous Michelson-Morley experiment is not mentioned in the 1905 relativity paper; but curiously Einstein did not mention Fizeau\\'s experimental result either, and this is puzzling in light of the importance of the experiment in Einstein\\'s pathway to his theory. In this paper I try to discuss this question. ']]\n",
      "--------------------------------------------------------------------------------\n",
      "Are we living in a simulation?\n",
      "--------------------------------------------------------------------------------\n",
      "[['  The Simulation Argument has gained significant traction in the public arena. It has offered a hypothesis based on probabilistic analysis of its assumptions that we are likely to exist within a computer simulation. This has been derived from factors including the prediction of computing power, human existence, extinction and population dynamics, and suggests a very large value for the number of possible simulations within which we may exist. On evaluating this argument through the application of tangible real-world evidence and projections, it is possible to calculate real numerical solutions for the Simulation Argument. This reveals a much smaller number of possible simulations within which we may exist, and offers a novel practicable approach in which to appraise the variety and multitude of conjectures and theories associated with the Simulation Hypothesis. '\n",
      "  '  The Simulation Argument posed by Bostrom (2003) suggests that we may be living inside a sophisticated computer simulation. If post-human civilizations eventually have both the capability and desire to generate such Bostrom-like simulations, then the number of simulated realities would greatly exceed the one base reality, ostensibly indicating a high probability that we do not live in said base reality. In this work, it is argued that since the hypothesis that such simulations are technically possible remains unproven, then statistical calculations need to consider not just the number of state spaces, but the intrinsic model uncertainty. This is achievable through a Bayesian treatment of the problem, which is presented here. Using Bayesian model averaging, it is shown that the probability that we are sims is in fact less than 50%, tending towards that value in the limit of an infinite number of simulations. This result is broadly indifferent as to whether one conditions upon the fact that humanity has not yet birthed such simulations, or ignore it. As argued elsewhere, it is found that if humanity does start producing such simulations, then this would radically shift the odds and make it very probable that we are in fact sims. ']]\n",
      "--------------------------------------------------------------------------------\n",
      "Why is the Transformer architecture more scalable than LSTM?\n",
      "--------------------------------------------------------------------------------\n",
      "[['  With the recent developments in the field of Natural Language Processing, there has been a rise in the use of different architectures for Neural Machine Translation. Transformer architectures are used to achieve state-of-the-art accuracy, but they are very computationally expensive to train. Everyone cannot have such setups consisting of high-end GPUs and other resources. We train our models on low computational resources and investigate the results. As expected, transformers outperformed other architectures, but there were some surprising results. Transformers consisting of more encoders and decoders took more time to train but had fewer BLEU scores. LSTM performed well in the experiment and took comparatively less time to train than transformers, making it suitable to use in situations having time constraints. '\n",
      "  '  There have been a lot of interest in the scaling properties of Transformer models. However, not much has been done on the front of investigating the effect of scaling properties of different inductive biases and model architectures. Do model architectures scale differently? If so, how does inductive bias affect scaling behaviour? How does this influence upstream (pretraining) and downstream (transfer)? This paper conducts a systematic study of scaling behaviour of ten diverse model architectures such as Transformers, Switch Transformers, Universal Transformers, Dynamic convolutions, Performers, and recently proposed MLP-Mixers. Via extensive experiments, we show that (1) architecture is an indeed an important consideration when performing scaling and (2) the best performing model can fluctuate at different scales. We believe that the findings outlined in this work has significant implications to how model architectures are currently evaluated in the community. ']]\n",
      "--------------------------------------------------------------------------------\n",
      "What is the role of quantum mechanics in biology?\n",
      "--------------------------------------------------------------------------------\n",
      "[['  There have been many claims that quantum mechanics plays a key role in the origin and/or operation of biological organisms, beyond merely providing the basis for the shapes and sizes of biological molecules and their chemical affinities. These range from the suggestion by Schrodinger that quantum fluctuations produce mutations, to the conjecture by Hameroff and Penrose that quantum coherence in microtubules is linked to consciousness. I review some of these claims in this paper, and discuss the serious problem of decoherence. I advance some further conjectures about quantum information processing in bio-systems. Some possible experiments are suggested. '\n",
      "  '  Quantum physics and biology have long been regarded as unrelated disciplines, describing nature at the inanimate microlevel on the one hand and living species on the other hand. Over the last decades the life sciences have succeeded in providing ever more and refined explanations of macroscopic phenomena that were based on an improved understanding of molecular structures and mechanisms. Simultaneously, quantum physics, originally rooted in a world view of quantum coherences, entanglement and other non-classical effects, has been heading towards systems of increasing complexity. The present perspective article shall serve as a pedestrian guide to the growing interconnections between the two fields. We recapitulate the generic and sometimes unintuitive characteristics of quantum physics and point to a number of applications in the life sciences. We discuss our criteria for a future quantum biology, its current status, recent experimental progress and also the restrictions that nature imposes on bold extrapolations of quantum theory to macroscopic phenomena. ']]\n",
      "--------------------------------------------------------------------------------\n",
      "What is the role of dark matter in the universe?\n",
      "--------------------------------------------------------------------------------\n",
      "[['  This paper provides a review of the variants of dark matter (CDM, HDM) which are thought to be fundamental components of the universe and their role in origin and evolution of structures. '\n",
      "  '  Models of structure formation in the universe postulate that matter distributions observed today in galaxy catalogs arise, through a complex non-linear dynamics, by gravitational evolution from a very uniform initial state. Dark matter plays the central role of providing the primordial density seeds which will govern the dynamics of structure formation. We critically examine the role of cosmological dark matter by considering three different and related issues: Basic statistical properties of theoretical initial density fields, several elements of the gravitational many-body dynamics and key correlation features of the observed galaxy distributions are discussed, stressing some useful analogies with known systems in modern statistical physics. ']]\n",
      "--------------------------------------------------------------------------------\n",
      "What are the recent developments in climate change research?\n",
      "--------------------------------------------------------------------------------\n",
      "[['  Climate change is an important current issue and there is much debate about the causes and effects. This article examines the changes in our climate, comparing the recent changes with those in the past. There have been changes in temperature, resulting in an average global rise over the last 300 years, as well as widespread melting of snow and ice, and rising global average sea level. There are many theories for the causes of the recent change in the climate, including some natural and some human influenced. The most widely believed cause of the climate change is increasing levels of Greenhouse gases in the atmosphere and as the atmosphere plays an important role in making our planet inhabitable, it is important to understand it in order to protect it. However, there are other theories for the cause of climate change, the Sun and cosmic rays, for example, are felt by some to have a significant role to play. There is also well-established evidence that the three Milankovitch cycles change the amount and alter the distribution of sunlight over the Earth, heating and cooling it. There are many influences on our planet and they all have differing levels of impact. The purpose of this article is to review the present overall position and urge open, reasoned discussion of the problem. '\n",
      "  '  Important issues about climate change are summarized and discussed:   A large body of evidence shows that the world climate is getting warmer. Climate models give a consistent explanation of this observation once human-made emissions of greenhouse gases are taken into account. Furthermore, the main source of greenhouse gases comes from the burning of oil, gas and coal, mainly in the industrialized countries. Without any change of behaviour, the possible predicted consequences of this climate change for the coming decades are very disturbing. Today\\'s (in)action\\'s will have long-term consequences for the entire biosphere and the living conditions of many future generations.   The combination of the various points related to the climate change leads to a final question: \"For how long will Humanity continue to bury its head in the sand?\" ']]\n",
      "--------------------------------------------------------------------------------\n",
      "Are there alternatives to the Big Bang theory?\n",
      "--------------------------------------------------------------------------------\n",
      "[['  The cosmic inflation hypothesis, its relation to fundamental theory on the beginning of the universe, and the light that both shed on how the various elements and their relative amounts came into existence.   The fundamental factors controlling the origin of the universe ex nihilo are developed and from them the following alternative hypotheses are developed and presented:   - an alternative to the inflation hypothesis, the purpose of which hypothesis is to explain how the structure in the universe developed from the initially unstructured and symmetrical Big Bang, and   - an alternative to the hypothesis that the various elements in the universe were formed by nuclear fusion in stars [not denying that it may occur occasionally]. '\n",
      "  '  Standard big bang nucleosynthesis (SBBN) has been remarkably successful, and it may well be the correct and sufficient account of what happened. However, interest in variations from the standard picture come from two sources: First, big bang nucleosynthesis can be used to constrain physics of the early universe. Second, there may be some discrepancy between predictions of SBBN and observations of abundances. Various alternatives to SBBN include inhomogeneous nucleosynthesis, nucleosynthesis with antimatter, and nonstandard neutrino physics. ']]\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def query_abstract(query, prompt=\"Represent the query for retrieving relevant research paper abstracts:\", k=5):\n",
    "    query_vector = model_ins.encode(\n",
    "        sentences=[[prompt, query]],\n",
    "        batch_size=1,\n",
    "        device=str(device)\n",
    "    )\n",
    "    return search(query_vector, k=k)\n",
    "\n",
    "questions = [\n",
    "    \"Who else than Einstein developed relativity independently?\",\n",
    "    \"Are we living in a simulation?\",\n",
    "    \"Why is the Transformer architecture more scalable than LSTM?\",\n",
    "    \"What is the role of quantum mechanics in biology?\",\n",
    "    \"What is the role of dark matter in the universe?\",\n",
    "    \"What are the recent developments in climate change research?\",\n",
    "    \"Are there alternatives to the Big Bang theory?\",\n",
    "]\n",
    "for question in questions:\n",
    "    print(question)\n",
    "    print('-'*80)\n",
    "    print(query_abstract(question, k=2)[1])\n",
    "    print('-'*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7b2319-ee6b-4b6c-852e-fb1b3470c585",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "It's working quite good!\n",
    "\n",
    "### Counting the bits\n",
    "\n",
    "The `Instruct-XL` model is 5 GB when stored in the disk, and about 10.5 GB when loaded onto the GPU VRAM. \n",
    "\n",
    "To estimate the FAISS index size, we have to serialize it first. It comes out to be 6.4 GB.\n",
    "\n",
    "The Pandas dataframe is just 2.5 GB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "c227f3ab-3bc8-4975-a7a8-7a4b9efe55e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instructor-XL model has size 4.6258 GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "def size_of_model(model):\n",
    "    torch.save(model.state_dict(), 'temp.p')\n",
    "    size = os.path.getsize('temp.p')\n",
    "    os.remove('temp.p')\n",
    "    return size\n",
    "\n",
    "print(f\"Instructor-XL model has size {size_of_model(model_ins)/(2**30):.4f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "17394d59-0ebe-4814-9d18-939248c6fed9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index has size 6.4493 GB\n"
     ]
    }
   ],
   "source": [
    "def size_of_faiss_index(index):\n",
    "    byte_array = faiss.serialize_index(index)\n",
    "    return sys.getsizeof(byte_array)\n",
    "\n",
    "print(f\"FAISS index has size {size_of_faiss_index(index)/(2**30):.4f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "1dde40d4-8746-4db3-a49b-d8af8cecf403",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total abstract dataset as a Pandas DataFrame has size 2.4744 GB\n"
     ]
    }
   ],
   "source": [
    "def size_of_dataframe(df):\n",
    "    return df.memory_usage(deep=True).sum()\n",
    "\n",
    "print(f\"Total abstract dataset as a Pandas DataFrame has size {size_of_dataframe(cdf)/(2**30):.4f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2349295d-727f-4782-96ce-d992bd7ddc31",
   "metadata": {},
   "source": [
    "## Exploring the titles dataset\n",
    "\n",
    "We can do the same exploration with the titles dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "e2fb96a4-cea4-438b-8ed1-e50616d5b027",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del cdf\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "a7b96cce-e4e6-4879-b41c-e04d5dcb6919",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filepaths = glob.glob(os.path.join(directory_path, 'titles_*.parquet'))\n",
    "dfs = []\n",
    "for filepath in filepaths:\n",
    "    df = pd.read_parquet(filepath)\n",
    "    dfs.append(df)\n",
    "\n",
    "cdf = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "27f9f586-3d70-409b-860d-08b8c88e0d38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>doi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Calculation of prompt diphoton production cros...</td>\n",
       "      <td>[-0.050620172, 0.041436385, 0.05363288, -0.029...</td>\n",
       "      <td>0704.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sparsity-certifying Graph Decompositions</td>\n",
       "      <td>[0.014515653, 0.023809524, -0.028145121, -0.04...</td>\n",
       "      <td>0704.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The evolution of the Earth-Moon system based o...</td>\n",
       "      <td>[-4.766115e-05, 0.017415706, 0.04146007, -0.03...</td>\n",
       "      <td>0704.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A determinant of Stirling cycle numbers counts...</td>\n",
       "      <td>[0.027208889, 0.046175897, 0.0010913888, -0.01...</td>\n",
       "      <td>0704.0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From dyadic $\\Lambda_{\\alpha}$ to $\\Lambda_{\\a...</td>\n",
       "      <td>[0.0113909235, 0.0042667952, -0.0008565594, -0...</td>\n",
       "      <td>0704.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2254193</th>\n",
       "      <td>Thermodynamics of Black Holes in Rastall Gravity</td>\n",
       "      <td>[0.02459273, 0.024434721, 0.025344433, 0.04852...</td>\n",
       "      <td>1710.04612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2254194</th>\n",
       "      <td>Tractable ADMM Schemes for Computing KKT Point...</td>\n",
       "      <td>[-0.010883444, 0.0013427543, 0.0028294649, -0....</td>\n",
       "      <td>1710.04613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2254195</th>\n",
       "      <td>Mono: an algebraic study of torus closures</td>\n",
       "      <td>[0.0011102908, -0.022653135, 0.054966096, -0.0...</td>\n",
       "      <td>1710.04614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2254196</th>\n",
       "      <td>Deep Imitation Learning for Complex Manipulati...</td>\n",
       "      <td>[0.039771307, -0.010292426, 0.0242721, -0.0688...</td>\n",
       "      <td>1710.04615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2254197</th>\n",
       "      <td>The Fornax Deep Survey (FDS) with the VST: III...</td>\n",
       "      <td>[-0.011371385, 0.0007478248, 0.020183152, -0.0...</td>\n",
       "      <td>1710.04616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2254198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     title  \\\n",
       "0        Calculation of prompt diphoton production cros...   \n",
       "1                 Sparsity-certifying Graph Decompositions   \n",
       "2        The evolution of the Earth-Moon system based o...   \n",
       "3        A determinant of Stirling cycle numbers counts...   \n",
       "4        From dyadic $\\Lambda_{\\alpha}$ to $\\Lambda_{\\a...   \n",
       "...                                                    ...   \n",
       "2254193   Thermodynamics of Black Holes in Rastall Gravity   \n",
       "2254194  Tractable ADMM Schemes for Computing KKT Point...   \n",
       "2254195         Mono: an algebraic study of torus closures   \n",
       "2254196  Deep Imitation Learning for Complex Manipulati...   \n",
       "2254197  The Fornax Deep Survey (FDS) with the VST: III...   \n",
       "\n",
       "                                                embeddings         doi  \n",
       "0        [-0.050620172, 0.041436385, 0.05363288, -0.029...   0704.0001  \n",
       "1        [0.014515653, 0.023809524, -0.028145121, -0.04...   0704.0002  \n",
       "2        [-4.766115e-05, 0.017415706, 0.04146007, -0.03...   0704.0003  \n",
       "3        [0.027208889, 0.046175897, 0.0010913888, -0.01...   0704.0004  \n",
       "4        [0.0113909235, 0.0042667952, -0.0008565594, -0...   0704.0005  \n",
       "...                                                    ...         ...  \n",
       "2254193  [0.02459273, 0.024434721, 0.025344433, 0.04852...  1710.04612  \n",
       "2254194  [-0.010883444, 0.0013427543, 0.0028294649, -0....  1710.04613  \n",
       "2254195  [0.0011102908, -0.022653135, 0.054966096, -0.0...  1710.04614  \n",
       "2254196  [0.039771307, -0.010292426, 0.0242721, -0.0688...  1710.04615  \n",
       "2254197  [-0.011371385, 0.0007478248, 0.020183152, -0.0...  1710.04616  \n",
       "\n",
       "[2254198 rows x 3 columns]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "5452d898-887f-40f2-b812-a8990ea5ae26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export_duplicates(cdf, \"output_titles.txt\", column='title')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e216fc8-2ca4-4766-9d8b-46eb93023224",
   "metadata": {},
   "source": [
    "Interesting things I found.\n",
    "\n",
    "Some really popular titles:\n",
    "* 13 \"Beyond the Standard Model\"\n",
    "* 9 \"Physics beyond the Standard Model\"\n",
    "* 6 \"Chiral perturbation theory\"\n",
    "* 6 \"CP Violation in Hyperon Decays\"\n",
    "* 5 \"CP violation\"\n",
    "Some papers are not informative: 2 \"Title Redacted\", 2 \"withdrawn\", 6 \"Rejoinder\".\n",
    "\n",
    "Some uncommon title types:\n",
    "* 73 starting with \"Comment on\" or \"Comment:\"\n",
    "* 129 starting with \"Discussion of\" or \"Discussion:\"\n",
    "* 11 \"Matters of gravity\", which turns out to be \"The newsletter of the Division of Gravitational Physics of the American Physical Society\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8cce5e-03d6-4864-bb5e-569ccad4a66d",
   "metadata": {},
   "source": [
    "### FAISS search\n",
    "\n",
    "Now just like what we did with abstracts, we can compile a FAISS vector search database and search over them, to find paper titles that might answer the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "a889ca15-f6e9-4fc2-b022-b4589bbb72e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Convert embeddings into a matrix (2D numpy array)\n",
    "embedding_matrix = np.vstack(cdf['embeddings'].values)\n",
    "\n",
    "# Get the dimension of the embeddings\n",
    "dimension = embedding_matrix.shape[1] \n",
    "\n",
    "# Build the FAISS index\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(embedding_matrix.astype('float32'))  # FAISS uses float32\n",
    "\n",
    "# Now, create a mapping from the index in the FAISS database to the corresponding doi and abstract.\n",
    "# The i-th entry in the FAISS index corresponds to the i-th entry in the DataFrame\n",
    "index_to_doi = cdf['doi'].values\n",
    "index_to_title = cdf['title'].values\n",
    "\n",
    "# Now, you can search the FAISS index\n",
    "def search(query_vector, k=5):\n",
    "    # Make sure query_vector is a 2D array\n",
    "    query_vector = query_vector.reshape(1, -1).astype('float32')\n",
    "    \n",
    "    _, indices = index.search(query_vector, k)\n",
    "    \n",
    "    # Convert indices to original DOIs and abstracts\n",
    "    result_doi = index_to_doi[indices]\n",
    "    result_title = index_to_title[indices]\n",
    "    result_title = np.array([[np.char.replace(s, '\\n', ' ') for s in row] for row in result_title])\n",
    "    \n",
    "    return result_doi, result_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "a17abab1-32e2-417d-847c-97566a60fe99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who else than Einstein developed relativity independently?\n",
      "--------------------------------------------------------------------------------\n",
      "[['Einstein and Hilbert: The Creation of General Relativity'\n",
      "  'From Newton to Einstein: the birth of Special Relativity'\n",
      "  \"Quanta: The Originality of Einstein's Approach to Relativity?\"\n",
      "  'A note on \"Einstein\\'s special relativity beyond the speed of light by   James M. Hill and Barry J. Cox\"'\n",
      "  'The contribution of Giordano Bruno to the principle of relativity'\n",
      "  \"A brief note on how Einstein's general relativity has influenced the   development of modern differential geometry\"\n",
      "  \"Beyond Einstein's General Relativity\"\n",
      "  'Connection independent formulation of general relativity'\n",
      "  \"Max Born, Albert Einstein and Hermann Minkowski's Space-Time Formalism   of Special Relativity\"\n",
      "  'Derivation of Einstein Cartan theory from General Relativity']]\n",
      "--------------------------------------------------------------------------------\n",
      "Are we living in a simulation?\n",
      "--------------------------------------------------------------------------------\n",
      "[['Do we live in a [quantum] simulation? Constraints, observations, and   experiments on the simulation hypothesis'\n",
      "  'Probability and consequences of living inside a computer simulation'\n",
      "  \"A type of simulation which some experimental evidence suggests we don't   live in\"\n",
      "  'Elements of a Theory of Simulation' 'On testing the simulation theory'\n",
      "  'How Many Simulations Do We Exist In? A Practical Mathematical Solution   to the Simulation Argument'\n",
      "  'Reality as a simulation of reality: robot illusions, fundamental limits,   and a physical demonstration'\n",
      "  'A Bayesian Approach to the Simulation Argument'\n",
      "  'Multiversal Simulacra: Understanding Hypotheticals and Possible Worlds   Through Simulation'\n",
      "  'Current Status of Simulations']]\n",
      "--------------------------------------------------------------------------------\n",
      "Why is the Transformer architecture more scalable than LSTM?\n",
      "--------------------------------------------------------------------------------\n",
      "[['Persformer: A Transformer Architecture for Topological Machine Learning'\n",
      "  'Language Modeling using LMUs: 10x Better Data Efficiency or Improved   Scaling Compared to Transformers'\n",
      "  'Redesigning the Transformer Architecture with Insights from   Multi-particle Dynamical Systems'\n",
      "  'GroupBERT: Enhanced Transformer Architecture with Efficient Grouped   Structures'\n",
      "  'PyramidTNT: Improved Transformer-in-Transformer Baselines with Pyramid   Architecture'\n",
      "  'Efficiently Scaling Transformer Inference'\n",
      "  'Comparative study of Transformer and LSTM Network with attention   mechanism on Image Captioning'\n",
      "  'Multilinguals at SemEval-2022 Task 11: Transformer Based Architecture   for Complex NER'\n",
      "  'Scalable Transformers for Neural Machine Translation'\n",
      "  'Perspectives and Prospects on Transformer Architecture for Cross-Modal   Tasks with Language and Vision']]\n",
      "--------------------------------------------------------------------------------\n",
      "What is the role of quantum mechanics in biology?\n",
      "--------------------------------------------------------------------------------\n",
      "[['What can biology bestow to quantum mechanics?' 'Quantum Biology'\n",
      "  'On the fundamental role of dynamics in quantum physics'\n",
      "  'Quantum physics meets biology'\n",
      "  'Quantum Information Biology: from information interpretation of quantum   mechanics to applications in molecular biology and cognitive psychology'\n",
      "  'The role of symmetry in the interpretation of quantum mechanics'\n",
      "  'Quantum mechanical formalism for biological evolution'\n",
      "  'Quantum mechanism of Biological Search'\n",
      "  'Quantum metrology and its application in biology'\n",
      "  'Loop Quantum Theory Applied to Biology and Nonlinear Whole Biology']]\n",
      "--------------------------------------------------------------------------------\n",
      "What is the role of dark matter in the universe?\n",
      "--------------------------------------------------------------------------------\n",
      "[['The role of dark matter in the galaxy mass-size relationship'\n",
      "  'Dark matter in the universe' 'Dark Matter of the Universe'\n",
      "  'Dark Matter in Cosmology'\n",
      "  'The role of Dark Matter interaction in galaxy clusters'\n",
      "  'Dark Matter in Astrophysics/Cosmology' 'Dark Matter Astrophysics'\n",
      "  'Dark Matter in Modern Cosmology' 'Cosmology and Dark Matter'\n",
      "  'Cosmology and Dark Matter']]\n",
      "--------------------------------------------------------------------------------\n",
      "What are the recent developments in climate change research?\n",
      "--------------------------------------------------------------------------------\n",
      "[['Comment to \"Recent Climate Observations Compared to Projections\" by   Rahmstorf et al'\n",
      "  'Climate Change Research in View of Bibliometrics'\n",
      "  'Climate Change and Open Science'\n",
      "  'Climate Change and Its Causes, A Discussion About Some Key Issues'\n",
      "  'BOUT++: Recent and current developments'\n",
      "  'The climate impact of ICT: A review of estimates, trends and regulations'\n",
      "  'A large-scale bibliometric analysis of global climate change research   between 2001 and 2018'\n",
      "  'Computing Research for the Climate Crisis'\n",
      "  'Recent developments in warm inflation'\n",
      "  'Progress and Prospects in Weather and Climate Modelling']]\n",
      "--------------------------------------------------------------------------------\n",
      "Are there alternatives to the Big Bang theory?\n",
      "--------------------------------------------------------------------------------\n",
      "[['An origin of the universe: a model alternative to Big Bang'\n",
      "  'Was There A Big Bang?' 'Another model for the regularized big bang'\n",
      "  'Thoughts on Big Bang'\n",
      "  'The Planck energy-mass source as an alternative to the Big Bang'\n",
      "  'Alternative Solutions to Big Bang Nucleosynthesis'\n",
      "  'Alternative ideas in cosmology'\n",
      "  'The big-bang theory: construction, evolution and status'\n",
      "  'On the Alternative Theories of Cosmology'\n",
      "  'Towards the Little Bang Standard Model']]\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def query_title(query, prompt=\"Represent the query for retrieving relevant research paper titles:\", k=5):\n",
    "    query_vector = model_ins.encode(\n",
    "        sentences=[[prompt, query]],\n",
    "        batch_size=1,\n",
    "        device=str(device)\n",
    "    )\n",
    "    return search(query_vector, k=k)\n",
    "\n",
    "questions = [\n",
    "    \"Who else than Einstein developed relativity independently?\",\n",
    "    \"Are we living in a simulation?\",\n",
    "    \"Why is the Transformer architecture more scalable than LSTM?\",\n",
    "    \"What is the role of quantum mechanics in biology?\",\n",
    "    \"What is the role of dark matter in the universe?\",\n",
    "    \"What are the recent developments in climate change research?\",\n",
    "    \"Are there alternatives to the Big Bang theory?\",\n",
    "]\n",
    "for question in questions:\n",
    "    print(question)\n",
    "    print('-'*80)\n",
    "    print(query_abstract(question, k=10)[1])\n",
    "    print('-'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d8ede6-3ce2-4795-bf3f-d6e34b3b46d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:faiss]",
   "language": "python",
   "name": "conda-env-faiss-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
